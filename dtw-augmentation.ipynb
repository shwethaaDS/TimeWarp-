{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMPh0eOrA6GTJyUNdq5McFz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install numpy pandas scipy matplotlib tensorflow keras"],"metadata":{"id":"L0EN2OWYjXn0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","project_path = '/content/drive/MyDrive/MSc SS/8th Sem/20XW87 - Data Mining Lab/DTW-Augmentation'\n","\n","import sys\n","sys.path.append(f'{project_path}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iy5-DsMGesfS","executionInfo":{"status":"ok","timestamp":1744864364224,"user_tz":-330,"elapsed":25208,"user":{"displayName":"21PW21 - RAM MURUGAN S","userId":"00559182924095047839"}},"outputId":"b1207611-bd94-4fef-cfa2-ca4c39d32a72"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**DTW**\n","\n","---\n","\n"],"metadata":{"id":"8XU7uGcLmrjh"}},{"cell_type":"markdown","source":["This code contains the implementation of the Dynamic Time Warping algorithm"],"metadata":{"id":"a0SagDnOmu5l"}},{"cell_type":"code","source":["import numpy as np\n","import sys\n","\n","def dynamic_time_warping(x: np.ndarray, y: np.ndarray, w: float = -1):\n","    x = np.atleast_2d(x)\n","    y = np.atleast_2d(y)\n","\n","    if x.ndim == 1:\n","        x = x[:, np.newaxis]\n","    if y.ndim == 1:\n","        y = y[:, np.newaxis]\n","\n","    if len(x) > len(y):\n","        x, y = y, x\n","\n","    lx, ly = len(x), len(y)\n","    r, c = lx + 1, ly + 1\n","\n","    w = max(1, int(w * max(lx, ly))) if w >= 0 else max(lx, ly)\n","\n","    D = np.zeros((r, c), dtype=np.float64)\n","    D[0, 1:] = sys.float_info.max\n","    D[1:, 0] = sys.float_info.max\n","\n","    dist = np.square(x[:, np.newaxis] - y).sum(axis=2)\n","    D[1:, 1:] = dist\n","\n","    for i in range(1, r):\n","        j_start = max(1, i - w)\n","        j_stop = min(c, i + w + 1)\n","        if i - w - 1 >= 0:\n","            D[i, i - w - 1] = sys.float_info.max\n","\n","        for j in range(j_start, j_stop):\n","            D[i, j] += min(D[i - 1, j], D[i, j - 1], D[i - 1, j - 1])\n","\n","        if j_stop < c:\n","            D[i, j_stop] = sys.float_info.max\n","\n","    return np.sqrt(D[lx, ly]), D\n"],"metadata":{"id":"QCOEc0n1mr1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilities used\n","\n","---\n","\n"],"metadata":{"id":"RCl-jE29ofM2"}},{"cell_type":"markdown","source":["**Constants**"],"metadata":{"id":"0bPOWQWBpEoO"}},{"cell_type":"code","source":["from dba import dba\n","\n","from distances.dtw.dtw import dynamic_time_warping as dtw\n","\n","from augment import get_weights_average_selected\n","\n","# UNIVARIATE_DATASET_NAMES = ['50words','Adiac','ArrowHead','Beef','BeetleFly',\n","#                             'BirdChicken','Car','CBF','ChlorineConcentration',\n","#                             'CinC_ECG_torso','Coffee','Computers','Cricket_X',\n","#                             'Cricket_Y','Cricket_Z','DiatomSizeReduction',\n","#                             'DistalPhalanxOutlineAgeGroup',\n","#                             'DistalPhalanxOutlineCorrect','DistalPhalanxTW',\n","#                             'Earthquakes','ECG200','ECG5000','ECGFiveDays',\n","#                             'ElectricDevices','FaceAll','FaceFour','FacesUCR',\n","#                             'FISH','FordA','FordB','Gun_Point','Ham',\n","#                             'HandOutlines','Haptics','Herring','InlineSkate',\n","#                             'InsectWingbeatSound','ItalyPowerDemand',\n","#                             'LargeKitchenAppliances','Lighting2','Lighting7',\n","#                             'MALLAT','Meat','MedicalImages',\n","#                             'MiddlePhalanxOutlineAgeGroup',\n","#                             'MiddlePhalanxOutlineCorrect','MiddlePhalanxTW',\n","#                             'MoteStrain','NonInvasiveFatalECG_Thorax1',\n","#                             'NonInvasiveFatalECG_Thorax2','OliveOil','OSULeaf',\n","#                             'PhalangesOutlinesCorrect','Phoneme','Plane',\n","#                             'ProximalPhalanxOutlineAgeGroup',\n","#                             'ProximalPhalanxOutlineCorrect',\n","#                             'ProximalPhalanxTW','RefrigerationDevices',\n","#                             'ScreenType','ShapeletSim','ShapesAll',\n","#                             'SmallKitchenAppliances','SonyAIBORobotSurface',\n","#                             'SonyAIBORobotSurfaceII','StarLightCurves',\n","#                             'Strawberry','SwedishLeaf','Symbols',\n","#                             'synthetic_control','ToeSegmentation1',\n","#                             'ToeSegmentation2','Trace','TwoLeadECG',\n","#                             'Two_Patterns','UWaveGestureLibraryAll',\n","#                             'uWaveGestureLibrary_X','uWaveGestureLibrary_Y',\n","#                             'uWaveGestureLibrary_Z','wafer','Wine',\n","#                             'WordsSynonyms','Worms','WormsTwoClass','yoga']\n","\n","UNIVARIATE_DATASET_NAMES = ['BirdChicken','Meat']\n","\n","UNIVARIATE_ARCHIVE_NAMES = ['UCR_TS_Archive_2015']\n","\n","AVERAGING_ALGORITHMS = {'dba':dba}\n","\n","DISTANCE_ALGORITHMS = {'dtw': dtw}\n","\n","DTW_PARAMS = {'w':-1} # warping window should be given in percentage (negative means no warping window)\n","\n","DISTANCE_ALGORITHMS_PARAMS = {'dtw':DTW_PARAMS}\n","\n","MAX_PROTOTYPES_PER_CLASS = 5\n","\n","WEIGHTS_METHODS = {'as':get_weights_average_selected }\n"],"metadata":{"id":"-Wg0G1rfpGEp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utils\n"],"metadata":{"id":"Han5aDYQohn_"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib\n","matplotlib.use('pdf')\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import adjusted_rand_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","import operator\n","from scipy.stats import wilcoxon\n","\n","from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n","from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n","from utils.constants import MAX_PROTOTYPES_PER_CLASS\n","\n","def zNormalize(x):\n","    x_mean = x.mean(axis=0) # mean for each dimension of time series x\n","    x_std = x.std(axis = 0) # std for each dimension of time series x\n","    x = (x - x_mean)/(x_std)\n","    return x\n","\n","def readucr(filename):\n","    data = np.loadtxt(filename, delimiter = ',')\n","    Y = data[:,0]\n","    X = data[:,1:]\n","    return X, Y\n","\n","def check_if_file_exits(file_name):\n","    return os.path.exists(file_name)\n","\n","def create_directory(directory_path):\n","    if os.path.exists(directory_path):\n","        return None\n","    else:\n","        try:\n","            os.makedirs(directory_path)\n","        except:\n","            # in case another machine created the path meanwhile\n","            return None\n","        return directory_path\n","\n","def transform_labels(y_train,y_test):\n","    \"\"\"\n","    Transform label to min equal zero and continuous\n","    For example if we have [1,3,4] --->  [0,1,2]\n","    \"\"\"\n","    # init the encoder\n","    encoder = LabelEncoder()\n","    # concat train and test to fit\n","    y_train_test = np.concatenate((y_train,y_test),axis =0)\n","    # fit the encoder\n","    encoder.fit(y_train_test)\n","    # transform to min zero and continuous labels\n","    new_y_train_test = encoder.transform(y_train_test)\n","    # resplit the train and test\n","    new_y_train = new_y_train_test[0:len(y_train)]\n","    new_y_test = new_y_train_test[len(y_train):]\n","    return new_y_train, new_y_test\n","\n","def read_all_datasets(root_dir,archive_name, sort_dataset_name = False):\n","    datasets_dict = {}\n","\n","    dataset_names_to_sort = []\n","\n","    for dataset_name in DATASET_NAMES:\n","        file_name = root_dir+archive_name+'/'+dataset_name+'/'+dataset_name\n","        x_train, y_train = readucr(file_name+'_TRAIN')\n","        x_test, y_test = readucr(file_name+'_TEST')\n","        datasets_dict[dataset_name] = (x_train.copy(),y_train.copy(),x_test.copy(),y_test.copy())\n","        dataset_names_to_sort.append((dataset_name,len(x_train)))\n","\n","    item_getter = 1\n","    if sort_dataset_name == True:\n","        item_getter = 0\n","    dataset_names_to_sort.sort(key=operator.itemgetter(item_getter))\n","\n","    for i in range(len(DATASET_NAMES)):\n","        DATASET_NAMES[i] = dataset_names_to_sort[i][0]\n","\n","    return datasets_dict\n","\n","def calculate_metrics(y_true, y_pred,duration,clustering=False):\n","    \"\"\"\n","    Return a data frame that contains the precision, accuracy, recall and the duration\n","    For clustering it applys the adjusted rand index\n","    \"\"\"\n","    if clustering == False:\n","        res = pd.DataFrame(data = np.zeros((1,5),dtype=float), index=[0],\n","            columns=['precision','accuracy','error','recall','duration'])\n","        res['precision'] = precision_score(y_true,y_pred,average='macro')\n","        res['accuracy'] = accuracy_score(y_true,y_pred)\n","        res['recall'] = recall_score(y_true,y_pred,average='macro')\n","        res['duration'] = duration\n","        res['error'] = 1-res['accuracy']\n","        return res\n","    else:\n","        res = pd.DataFrame(data = np.zeros((1,2),dtype=float), index=[0],\n","            columns=['ari','duration'])\n","        res['duration']=duration\n","        res['ari'] = adjusted_rand_score(y_pred,y_true)\n","        return res\n","\n","def dataset_is_ready_to_plot(df_res,dataset_name,archive_name,array_algorithm_names):\n","    for algorithm_name in array_algorithm_names:\n","                # if any algorithm algorithm is not finished do not plot\n","                if not any(df_res.loc[(df_res['dataset_name']==dataset_name) \\\n","                            & (df_res['archive_name']==archive_name)] \\\n","                            ['algorithm_name']==algorithm_name)\\\n","                                       or (df_res.loc[(df_res['dataset_name']==dataset_name) \\\n","                            & (df_res['archive_name']==archive_name)\\\n","                            & (df_res['algorithm_name']==algorithm_name)]\\\n","                                       ['nb_prototypes'].max()!=MAX_PROTOTYPES_PER_CLASS):\n","                    return False\n","    return True\n","\n","def init_empty_df_metrics():\n","    return pd.DataFrame(data = np.zeros((0,5),dtype=float), index=[],\n","        columns=['precision','accuracy','error','recall','duration'])\n","\n","def get_df_metrics_from_avg(avg_df_metrics):\n","    res = pd.DataFrame(data = np.zeros((1,5),dtype=float), index=[0],\n","        columns=['precision','accuracy','error','recall','duration'])\n","    res['accuracy'] = avg_df_metrics['accuracy'].mean()\n","    res['precision'] = avg_df_metrics['precision'].mean()\n","    res['error'] = avg_df_metrics['error'].mean()\n","    res['recall'] = avg_df_metrics['recall'].mean()\n","    res['duration'] = avg_df_metrics['duration'].mean()\n","    return res\n","\n","def get_df_metrics_from_avg_data_cluster(avg_df_metrics):\n","    res = pd.DataFrame(data = np.zeros((1,2),dtype=float), index=[0],\n","        columns=['ari','duration'])\n","    res['ari'] = avg_df_metrics['ari'].mean()\n","    res['duration'] = avg_df_metrics['duration'].mean()\n","    return res\n","\n","def read_dataset(root_dir,archive_name,dataset_name):\n","    datasets_dict = {}\n","\n","    file_name = root_dir+'/'+archive_name+'/'+dataset_name+'/'+dataset_name\n","    x_train, y_train = readucr(file_name+'_TRAIN')\n","    x_test, y_test = readucr(file_name+'_TEST')\n","    datasets_dict[dataset_name] = (x_train.copy(),y_train.copy(),x_test.copy(),\n","        y_test.copy())\n","\n","    return datasets_dict\n","\n","def plot_epochs_metric(hist, file_name, metric='loss'):\n","    plt.figure()\n","    plt.plot(hist.history[metric])\n","    plt.plot(hist.history['val_'+metric])\n","    plt.title('model '+metric)\n","    plt.ylabel(metric)\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.savefig(file_name)\n","    plt.close()\n","\n","def save_logs(output_directory, hist, y_pred, y_true,duration ):\n","    hist_df = pd.DataFrame(hist.history)\n","    hist_df.to_csv(output_directory+'history.csv', index=False)\n","\n","    df_metrics = calculate_metrics(y_true,y_pred, duration)\n","    df_metrics.to_csv(output_directory+'df_metrics.csv', index=False)\n","\n","    index_best_model = hist_df['loss'].idxmin()\n","    row_best_model = hist_df.loc[index_best_model]\n","\n","    df_best_model = pd.DataFrame(data = np.zeros((1,6),dtype=float) , index = [0],\n","        columns=['best_model_train_loss', 'best_model_val_loss', 'best_model_train_acc',\n","        'best_model_val_acc', 'best_model_learning_rate','best_model_nb_epoch'])\n","\n","    df_best_model['best_model_train_loss'] = row_best_model['loss']\n","    df_best_model['best_model_val_loss'] = row_best_model['val_loss']\n","    df_best_model['best_model_train_acc'] = row_best_model['accuracy']\n","    df_best_model['best_model_val_acc'] = row_best_model['val_accuracy']\n","    df_best_model['best_model_learning_rate'] = row_best_model['learning_rate']\n","    df_best_model['best_model_nb_epoch'] = index_best_model\n","\n","    df_best_model.to_csv(output_directory+'df_best_model.csv', index=False)\n","\n","    # for FCN there is no hyperparameters fine tuning - everything is static in code\n","\n","    # plot losses\n","    plot_epochs_metric(hist, output_directory+'epochs_loss.png')\n","\n","# visualizations pairwise plots for AALTD 2018\n","\n","def generate_results_csv(output_file_name, root_dir,root_dir_dataset_archive, add_bake_off=True):\n","    res = pd.DataFrame(data=np.zeros((0, 7), dtype=float), index=[],\n","                       columns=['classifier_name', 'archive_name', 'dataset_name',\n","                                'precision', 'accuracy', 'recall', 'duration'])\n","    CLASSIFIERS = ['resnet','resnet_augment','ensemble']\n","    ITERATIONS = 1\n","    for classifier_name in CLASSIFIERS:\n","        for archive_name in ARCHIVE_NAMES:\n","            datasets_dict = read_all_datasets(root_dir_dataset_archive, archive_name)\n","            for it in range(ITERATIONS):\n","                curr_archive_name = archive_name\n","                if it != 0:\n","                    curr_archive_name = curr_archive_name + '_itr_' + str(it)\n","                for dataset_name in datasets_dict.keys():\n","                    output_dir = root_dir + '/results/' + classifier_name + '/' \\\n","                                 + curr_archive_name + '/' + dataset_name + '/' + 'df_metrics.csv'\n","                    if not os.path.exists(output_dir):\n","                        continue\n","                    df_metrics = pd.read_csv(output_dir)\n","                    df_metrics['classifier_name'] = classifier_name\n","                    df_metrics['archive_name'] = archive_name\n","                    df_metrics['dataset_name'] = dataset_name\n","                    res = pd.concat((res, df_metrics), axis=0, sort=False)\n","\n","    res.to_csv(root_dir + output_file_name, index=False)\n","    # aggreagte the accuracy for iterations on same dataset\n","    res = pd.DataFrame({\n","        'accuracy': res.groupby(\n","            ['classifier_name', 'archive_name', 'dataset_name'])['accuracy'].mean()\n","    }).reset_index()\n","\n","    return res\n","\n","def plot_pairwise(root_dir,root_dir_dataset_archive, classifier_name_1, classifier_name_2,\n","                  res_df=None, title='', fig=None, color='green', label=None):\n","    if fig is None:\n","        plt.figure()\n","    else:\n","        plt.figure(fig)\n","\n","    if res_df is None:\n","        res_df = generate_results_csv('results.csv', root_dir,root_dir_dataset_archive)\n","\n","    sorted_df = res_df.loc[(res_df['classifier_name'] == classifier_name_1) | \\\n","                           (res_df['classifier_name'] == classifier_name_2)]. \\\n","        sort_values(['classifier_name', 'archive_name', 'dataset_name'])\n","    # number of classifier we are comparing is 2 since pairwise\n","    m = 2\n","    # get max nb of ready datasets\n","    # count the number of tested datasets per classifier\n","    df_counts = pd.DataFrame({'count': sorted_df.groupby(\n","        ['classifier_name']).size()}).reset_index()\n","    # get the maximum number of tested datasets\n","    max_nb_datasets = df_counts['count'].max()\n","    min_nb_datasets = df_counts['count'].min()\n","    # both classifiers should have finished\n","    assert (max_nb_datasets == min_nb_datasets)\n","\n","    data = np.array(sorted_df['accuracy']).reshape(m, max_nb_datasets).transpose()\n","\n","    # concat the dataset name and the archive name to put them in the columns s\n","    sorted_df['archive_dataset_name'] = sorted_df['archive_name'] + '__' + \\\n","                                        sorted_df['dataset_name']\n","    # create the data frame containg the accuracies\n","    df_data = pd.DataFrame(data=data, columns=np.sort([classifier_name_1, classifier_name_2]),\n","                           index=np.unique(sorted_df['archive_dataset_name']))\n","\n","    # # assertion\n","    # p1 = float(sorted_df.loc[(sorted_df['classifier_name'] == classifier_name_1) &\n","    #                          (sorted_df['dataset_name'] == 'Beef')]['accuracy'])\n","    # p2 = float(df_data[classifier_name_1]['UCR_TS_Archive_2015__Beef'])\n","    # assert (p1 == p2)\n","\n","    x = np.arange(start=0, stop=1, step=0.01)\n","    plt.xlim(xmax=1.02, xmin=0.0)\n","    plt.ylim(ymax=1.02, ymin=0.0)\n","\n","    plt.scatter(x=df_data[classifier_name_1], y=df_data[classifier_name_2], color='blue')\n","    # c=sorted_df['theme_colors'])\n","    plt.xlabel('without data augmentation', fontsize='large')\n","    plt.ylabel('with data augmentation', fontsize='large')\n","    plt.plot(x, x, color='black')\n","    # plt.legend(loc='upper left')\n","    plt.title(title)\n","\n","    uniq, counts = np.unique(df_data[classifier_name_1] < df_data[classifier_name_2], return_counts=True)\n","    print('Wins', counts[-1])\n","\n","    uniq, counts = np.unique(df_data[classifier_name_1] == df_data[classifier_name_2], return_counts=True)\n","    print('Draws', counts[-1])\n","\n","    uniq, counts = np.unique(df_data[classifier_name_1] > df_data[classifier_name_2], return_counts=True)\n","    print('Losses', counts[-1])\n","\n","    p_value = wilcoxon(df_data[classifier_name_1], df_data[classifier_name_2], zero_method='pratt')[1]\n","    print(p_value)\n","\n","    plt.savefig(root_dir + '/' + classifier_name_1 + '-' + classifier_name_2 + '_' + title + '.pdf'\n","                , bbox_inches='tight')"],"metadata":{"id":"4pFLPdehpBQL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**DBA**\n","\n","---\n","\n"],"metadata":{"id":"ZGGYsfAsiyGE"}},{"cell_type":"markdown","source":["Utilizes the DTW algorithm and assigns weights"],"metadata":{"id":"X_lOts-PoVLK"}},{"cell_type":"code","source":["import numpy as np\n","import utils\n","\n","def calculate_dist_matrix(tseries, dist_fun, dist_fun_params):\n","    N = len(tseries)\n","    pairwise_dist_matrix = np.zeros((N,N), dtype = np.float64)\n","    # pre-compute the pairwise distance\n","    for i in range(N-1):\n","        x = tseries[i]\n","        for j in range(i+1,N):\n","            y = tseries[j]\n","            dist = dist_fun(x,y,**dist_fun_params)[0]\n","            # because dtw returns the sqrt\n","            dist = dist*dist\n","            pairwise_dist_matrix[i,j] = dist\n","            # dtw is symmetric\n","            pairwise_dist_matrix[j,i] = dist\n","        pairwise_dist_matrix[i,i] = 0\n","    return pairwise_dist_matrix\n","\n","def medoid(tseries, dist_fun, dist_fun_params):\n","    \"\"\"\n","    Calculates the medoid of the given list of MTS\n","    :param tseries: The list of time series\n","    \"\"\"\n","    N = len(tseries)\n","    if N == 1 :\n","        return 0,tseries[0]\n","    pairwise_dist_matrix = calculate_dist_matrix(tseries, dist_fun,\n","                                                 dist_fun_params)\n","\n","    sum_dist = np.sum(pairwise_dist_matrix, axis = 0)\n","    min_idx = np.argmin(sum_dist)\n","    med = tseries[min_idx]\n","    return min_idx, med\n","\n","def _dba_iteration(tseries, avg, dist_fun, dist_fun_params,weights):\n","    \"\"\"\n","    Perform one weighted dba iteration and return the new average\n","    \"\"\"\n","    # the number of time series in the set\n","    n = len(tseries)\n","    # length of the time series\n","    ntime = avg.shape[0]\n","    # number of dimensions (useful for MTS)\n","    num_dim = avg.shape[1]\n","    # array containing the new weighted average sequence\n","    new_avg = np.zeros((ntime,num_dim),dtype=np.float64)\n","    # array of sum of weights\n","    sum_weights = np.zeros((ntime,num_dim),dtype=np.float64)\n","    # loop the time series\n","    for s in range(n):\n","        series = tseries[s]\n","        dtw_dist, dtw = dist_fun(avg, series, **dist_fun_params)\n","\n","        i = ntime\n","        j = series.shape[0]\n","        while i >= 1 and j >= 1:\n","            new_avg[i-1] += series[j-1]*weights[s]\n","            sum_weights[i-1] += weights[s]\n","\n","            a = dtw[i - 1, j - 1]\n","            b = dtw[i, j - 1]\n","            c = dtw[i - 1, j]\n","            if a < b:\n","                if a < c:\n","                    # a is the minimum\n","                    i -= 1\n","                    j -= 1\n","                else:\n","                    # c is the minimum\n","                    i -=1\n","            else:\n","                if b < c:\n","                    # b is the minimum\n","                    j -= 1\n","                else:\n","                    # c is the minimum\n","                    i -= 1\n","    # update the new weighted avgerage\n","    new_avg = new_avg/sum_weights\n","\n","    return new_avg\n","\n","def dba(tseries, max_iter =10, verbose=False, init_avg_method = 'medoid',\n","        init_avg_series = None, distance_algorithm = 'dtw', weights=None):\n","    \"\"\"\n","    Computes the Dynamic Time Warping (DTW) Barycenter Averaging (DBA) of a\n","    group of Multivariate Time Series (MTS).\n","    :param tseries: A list containing the series to be averaged, where each\n","        MTS has a shape (l,m) where l is the length of the time series and\n","        m is the number of dimensions of the MTS - in the case of univariate\n","        time series m should be equal to one\n","    :param max_iter: The maximum number of iterations for the DBA algorithm.\n","    :param verbose: If true, then provide helpful output.\n","    :param init_avg_method: Either:\n","        'random' the average will be initialized by a random time series,\n","        'medoid'(default) the average will be initialized by the medoid of tseries,\n","        'manual' the value in init_avg_series will be used to initialize the average\n","    :param init_avg_series: this will be taken as average initialization if\n","        init_avg_method is set to 'manual'\n","    :param distance_algorithm: Determine which distance to use when aligning\n","        the time series\n","    :param weights: An array containing the weights to calculate a weighted dba\n","        (NB: for MTS each dimension should have its own set of weights)\n","        expected shape is (n,m) where n is the number of time series in tseries\n","        and m is the number of dimensions\n","    \"\"\"\n","    # get the distance function\n","    dist_fun = utils.constants.DISTANCE_ALGORITHMS[distance_algorithm]\n","    # get the distance function params\n","    dist_fun_params = utils.constants.DISTANCE_ALGORITHMS_PARAMS[distance_algorithm]\n","    # check if given dataset is empty\n","    if len(tseries)==0:\n","        # then return a random time series because the average cannot be computed\n","        start_idx = np.random.randint(0,len(tseries))\n","        return np.copy(tseries[start_idx])\n","\n","    # init DBA\n","    if init_avg_method == 'medoid':\n","        avg = np.copy(medoid(tseries,dist_fun, dist_fun_params)[1])\n","    elif init_avg_method == 'random':\n","        start_idx = np.random.randint(0,len(tseries))\n","        avg = np.copy(tseries[start_idx])\n","    else: # init with the given init_avg_series\n","        avg = np.copy(init_avg_series)\n","\n","    if len(tseries) == 1:\n","        return avg\n","    if verbose == True:\n","        print('Doing iteration')\n","\n","    # main DBA loop\n","    for i in range(max_iter):\n","        if verbose == True:\n","            print(' ',i,'...')\n","        if weights is None:\n","            # when giving all time series a weight equal to one we have the\n","            # non - weighted version of DBA\n","            weights = np.ones((len(tseries),tseries[0].shape[1]), dtype=np.float64)\n","        # dba iteration\n","        avg = _dba_iteration(tseries,avg,dist_fun, dist_fun_params,weights)\n","\n","    return avg\n"],"metadata":{"id":"pNiDWOidiyWV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["KNN alogorithm"],"metadata":{"id":"UV5OurTJi_ZS"}},{"cell_type":"code","source":["import numpy as np\n","import operator\n","import utils\n","\n","def get_neighbors(x_train, x_test_instance, k, dist_fun, dist_fun_params,\n","                  pre_computed_matrix=None, index_test_instance=None,\n","                  return_distances = False):\n","    \"\"\"\n","    Given a test instance, this function returns its neighbors present in x_train\n","    NB: If k==0 zero it only returns the distances\n","    \"\"\"\n","    distances = []\n","    # loop through the training set\n","    for i in range(len(x_train)):\n","        # calculate the distance between the test instance and each training instance\n","        if pre_computed_matrix is None:\n","            dist , _ = dist_fun(x_test_instance, x_train[i],**dist_fun_params)\n","        else:\n","            # do not re-compute the distance just get it from the precomputed one\n","            dist = pre_computed_matrix[i,index_test_instance]\n","        # add the index of the current training instance and its corresponding distance\n","        distances.append((i, dist))\n","    # if k (nb_neighbors) is zero return all the items with their distances\n","    # NOT SORTED\n","    if k==0:\n","        if return_distances == True:\n","            return distances\n","        else:\n","            print('Not implemented yet')\n","            exit()\n","    # sort list by specifying the second item to be sorted on\n","    distances.sort(key=operator.itemgetter(1))\n","    # else do return only the k nearest neighbors\n","    neighbors = []\n","    for i in range(k):\n","        if return_distances == True:\n","            # add the index and the distance of the k nearest instances from the train set\n","            neighbors.append(distances[i])\n","        else:\n","            # add only the index of the k nearest instances from the train set\n","            neighbors.append(distances[i][0])\n","\n","    return neighbors\n","\n"],"metadata":{"id":"rkOAHQsvi_pz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data augmentation Implementation**\n","\n","---\n","\n"],"metadata":{"id":"DmUrzpFHeL4d"}},{"cell_type":"markdown","source":["Generating synthetic time series to augment sparse datasets\n"],"metadata":{"id":"nKGATfOMqNYM"}},{"cell_type":"code","source":["# this contains the data generation methods of icdm 2017\n","import numpy as np\n","import random\n","import utils\n","\n","from dba import calculate_dist_matrix\n","from dba import dba\n","from knn import get_neighbors\n","\n","# weights calculation method : Average Selected (AS)\n","def get_weights_average_selected(x_train, dist_pair_mat, distance_algorithm='dtw'):\n","    # get the distance function\n","    dist_fun = utils.constants.DISTANCE_ALGORITHMS[distance_algorithm]\n","    # get the distance function params\n","    dist_fun_params = utils.constants.DISTANCE_ALGORITHMS_PARAMS[distance_algorithm]\n","    # get the number of dimenions\n","    num_dim = x_train[0].shape[1]\n","    # number of time series\n","    n = len(x_train)\n","    # maximum number of K for KNN\n","    max_k = 5\n","    # maximum number of sub neighbors\n","    max_subk = 2\n","    # get the real k for knn\n","    k = min(max_k,n-1)\n","    # make sure\n","    subk = min(max_subk,k)\n","    # the weight for the center\n","    weight_center = 0.5\n","    # the total weight of the neighbors\n","    weight_neighbors = 0.3\n","    # total weight of the non neighbors\n","    weight_remaining = 1.0- weight_center - weight_neighbors\n","    # number of non neighbors\n","    n_others = n - 1 - subk\n","    # get the weight for each non neighbor\n","    if n_others == 0 :\n","        fill_value = 0.0\n","    else:\n","        fill_value = weight_remaining/n_others\n","    # choose a random time series\n","    idx_center = random.randint(0,n-1)\n","    # get the init dba\n","    init_dba = x_train[idx_center]\n","    # init the weight matrix or vector for univariate time series\n","    weights = np.full((n,num_dim),fill_value,dtype=np.float64)\n","    # fill the weight of the center\n","    weights[idx_center] = weight_center\n","    # find the top k nearest neighbors\n","    topk_idx = np.array(get_neighbors(x_train,init_dba,k,dist_fun,dist_fun_params,\n","                         pre_computed_matrix=dist_pair_mat,\n","                         index_test_instance= idx_center))\n","    # select a subset of the k nearest neighbors\n","    final_neighbors_idx = np.random.permutation(k)[:subk]\n","    # adjust the weight of the selected neighbors\n","    weights[topk_idx[final_neighbors_idx]] = weight_neighbors / subk\n","    # return the weights and the instance with maximum weight (to be used as\n","    # init for DBA )\n","    return weights, init_dba\n","\n","def augment_train_set(x_train, y_train, classes, N, dba_iters=5,\n","                      weights_method_name = 'aa', distance_algorithm='dtw',\n","                      limit_N = True):\n","    \"\"\"\n","    This method takes a dataset and augments it using the method in icdm2017.\n","    :param x_train: The original train set\n","    :param y_train: The original labels set\n","    :param N: The number of synthetic time series.\n","    :param dba_iters: The number of dba iterations to converge.\n","    :param weights_method_name: The method for assigning weights (see constants.py)\n","    :param distance_algorithm: The name of the distance algorithm used (see constants.py)\n","    \"\"\"\n","    # get the weights function\n","    weights_fun = utils.constants.WEIGHTS_METHODS[weights_method_name]\n","    # get the distance function\n","    dist_fun = utils.constants.DISTANCE_ALGORITHMS[distance_algorithm]\n","    # get the distance function params\n","    dist_fun_params = utils.constants.DISTANCE_ALGORITHMS_PARAMS[distance_algorithm]\n","    # synthetic train set and labels\n","    synthetic_x_train = []\n","    synthetic_y_train = []\n","    # loop through each class\n","    for c in classes:\n","        # get the MTS for this class\n","        c_x_train = x_train[np.where(y_train==c)]\n","\n","        if len(c_x_train) == 1 :\n","            # skip if there is only one time series per set\n","            continue\n","\n","        if limit_N == True:\n","            # limit the nb_prototypes\n","            nb_prototypes_per_class = min(N, len(c_x_train))\n","        else:\n","            # number of added prototypes will re-balance classes\n","            nb_prototypes_per_class = N + (N-len(c_x_train))\n","\n","        # get the pairwise matrix\n","        if weights_method_name == 'aa':\n","            # then no need for dist_matrix\n","            dist_pair_mat = None\n","        else:\n","            dist_pair_mat = calculate_dist_matrix(c_x_train,dist_fun,dist_fun_params)\n","        # loop through the number of synthtectic examples needed\n","        for n in range(nb_prototypes_per_class):\n","            # get the weights and the init for avg method\n","            weights, init_avg = weights_fun(c_x_train,dist_pair_mat,\n","                                            distance_algorithm=distance_algorithm)\n","            # get the synthetic data\n","            synthetic_mts = dba(c_x_train, dba_iters, verbose=False,\n","                            distance_algorithm=distance_algorithm,\n","                            weights=weights,\n","                            init_avg_method = 'manual',\n","                            init_avg_series = init_avg)\n","            # add the synthetic data to the synthetic train set\n","            synthetic_x_train.append(synthetic_mts)\n","            # add the corresponding label\n","            synthetic_y_train.append(c)\n","    # return the synthetic set\n","    return np.array(synthetic_x_train), np.array(synthetic_y_train)\n","\n"],"metadata":{"id":"kTwbjyMvihf0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ensemble Models\n","\n","---\n","\n"],"metadata":{"id":"gkGWpCVLi1Hy"}},{"cell_type":"markdown","source":["The augmented data can be tested out using ensemble models"],"metadata":{"id":"qAARqSTpqk8U"}},{"cell_type":"code","source":["import keras\n","import numpy as np\n","from utils.utils import calculate_metrics\n","import gc\n","\n","class Classifier_ENSEMBLE:\n","    def __init__(self, output_directory, input_shape, nb_classes, verbose=False):\n","        self.output_directory = output_directory\n","        self.model1 = keras.models.load_model(self.output_directory.\n","                                    replace('ensemble','resnet')\n","                                    +'best_model.hdf5')\n","        self.model2 = keras.models.load_model(self.output_directory.\n","                                    replace('ensemble','resnet_augment')\n","                                    +'best_model.hdf5')\n","        if (verbose == True):\n","            self.model1.summary()\n","            self.model2.summary()\n","        self.verbose = verbose\n","\n","    def fit(self, x_test, y_true):\n","        # no training since models are pre-trained\n","\n","        y_pred1 = self.model1.predict(x_test)\n","        y_pred2 = self.model2.predict(x_test)\n","\n","        y_pred = (y_pred1+y_pred2)/2\n","\n","        # convert the predicted from binary to integer\n","        y_pred = np.argmax(y_pred, axis=1)\n","\n","        df_metrics = calculate_metrics(y_true, y_pred, 0.0)\n","\n","        df_metrics.to_csv(self.output_directory+'df_metrics.csv', index=False)\n","\n","        keras.backend.clear_session()\n","\n","        gc.collect()"],"metadata":{"id":"KTlshpf2i1W8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["RESNET classifier\n","\n","---\n","\n"],"metadata":{"id":"6ctI1sMSjLNL"}},{"cell_type":"markdown","source":["The augmented data can be tested out using resnet classifier"],"metadata":{"id":"28fja8egquTJ"}},{"cell_type":"code","source":["\n","import keras\n","import numpy as np\n","import sklearn\n","from utils.utils import save_logs\n","\n","class Classifier_RESNET:\n","\n","    def __init__(self, output_directory, input_shape, nb_classes,nb_prototypes,classes,\n","                 verbose=False,load_init_weights = False):\n","        self.output_directory = output_directory\n","        self.model = self.build_model(input_shape, nb_classes)\n","        self.nb_prototypes = nb_prototypes\n","        self.classes = classes\n","        if(verbose==True):\n","            self.model.summary()\n","        self.verbose = verbose\n","        if load_init_weights == True:\n","            self.model.load_weights(self.output_directory.\n","                                    replace('resnet_augment','resnet')\n","                                    +'/model_init.weights.h5')\n","        else:\n","            # this is without data augmentation so we should save inital non trained weights\n","            # to be used later as initialization and train the model with data augmentaiton\n","            self.model.save_weights(self.output_directory + 'model_init.weights.h5')\n","\n","    def build_model(self, input_shape, nb_classes):\n","        n_feature_maps = 64\n","\n","        input_layer = keras.layers.Input(input_shape)\n","\n","        # BLOCK 1\n","\n","        conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n","        conv_x = keras.layers.BatchNormalization()(conv_x)\n","        conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","        conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n","        conv_y = keras.layers.BatchNormalization()(conv_y)\n","        conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","        conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n","        conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","        # expand channels for the sum\n","        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n","        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","        output_block_1 = keras.layers.add([shortcut_y, conv_z])\n","        output_block_1 = keras.layers.Activation('relu')(output_block_1)\n","\n","        # BLOCK 2\n","\n","        conv_x = keras.layers.Conv1D(filters=n_feature_maps*2, kernel_size=8, padding='same')(output_block_1)\n","        conv_x = keras.layers.BatchNormalization()(conv_x)\n","        conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","        conv_y = keras.layers.Conv1D(filters=n_feature_maps*2, kernel_size=5, padding='same')(conv_x)\n","        conv_y = keras.layers.BatchNormalization()(conv_y)\n","        conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","        conv_z = keras.layers.Conv1D(filters=n_feature_maps*2, kernel_size=3, padding='same')(conv_y)\n","        conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","        # expand channels for the sum\n","        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps*2, kernel_size=1, padding='same')(output_block_1)\n","        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","        output_block_2 = keras.layers.add([shortcut_y, conv_z])\n","        output_block_2 = keras.layers.Activation('relu')(output_block_2)\n","\n","        # BLOCK 3\n","\n","        conv_x = keras.layers.Conv1D(filters=n_feature_maps*2, kernel_size=8, padding='same')(output_block_2)\n","        conv_x = keras.layers.BatchNormalization()(conv_x)\n","        conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","        conv_y = keras.layers.Conv1D(filters=n_feature_maps*2, kernel_size=5, padding='same')(conv_x)\n","        conv_y = keras.layers.BatchNormalization()(conv_y)\n","        conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","        conv_z = keras.layers.Conv1D(filters=n_feature_maps*2, kernel_size=3, padding='same')(conv_y)\n","        conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","        # no need to expand channels because they are equal\n","        shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n","\n","        output_block_3 = keras.layers.add([shortcut_y, conv_z])\n","        output_block_3 = keras.layers.Activation('relu')(output_block_3)\n","\n","        # FINAL\n","\n","        gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n","\n","        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n","\n","        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n","\n","        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n","            metrics=['accuracy'])\n","\n","        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n","\n","        file_path = self.output_directory+'best_model.h5'\n","\n","        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n","            save_best_only=True)\n","\n","        self.callbacks = [reduce_lr,model_checkpoint]\n","\n","        return model\n","\n","    def fit(self, x_train, y_train, x_test,y_true):\n","        # convert to binary\n","        # transform the labels from integers to one hot vectors\n","        self.enc = sklearn.preprocessing.OneHotEncoder()\n","        self.enc.fit(np.concatenate((y_train,y_true),axis=0).reshape(-1,1))\n","        y_train_int = y_train\n","        y_train = self.enc.transform(y_train.reshape(-1,1)).toarray()\n","        y_test = self.enc.transform(y_true.reshape(-1,1)).toarray()\n","\n","        # x_val and y_val are only used to monitor the test loss and NOT for training\n","        batch_size = 16\n","\n","        nb_epochs = 1\n","\n","        mini_batch_size = int(min(x_train.shape[0]/10, batch_size))\n","\n","        if len(x_train)>4000: # for ElectricDevices\n","            mini_batch_size = 128\n","\n","        hist=self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n","                verbose=self.verbose, validation_data=(x_test,y_test) ,callbacks=self.callbacks)\n","\n","        model = keras.models.load_model(self.output_directory+'best_model.h5')\n","\n","        y_pred = model.predict(x_test)\n","\n","        # convert the predicted from binary to integer\n","        y_pred = np.argmax(y_pred , axis=1)\n","\n","        keras.backend.clear_session()\n","\n","        save_logs(self.output_directory, hist, y_pred, y_true, 0.0)\n","\n","        return y_pred"],"metadata":{"id":"dH0h2As1jLdy","executionInfo":{"status":"ok","timestamp":1744864376953,"user_tz":-330,"elapsed":12749,"user":{"displayName":"21PW21 - RAM MURUGAN S","userId":"00559182924095047839"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Main implementation"],"metadata":{"id":"ZfOPYPLfjDM7"}},{"cell_type":"code","source":["from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n","from utils.constants import MAX_PROTOTYPES_PER_CLASS\n","from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n","\n","from utils.utils import read_all_datasets\n","from utils.utils import calculate_metrics\n","from utils.utils import transform_labels\n","from utils.utils import create_directory\n","from utils.utils import plot_pairwise\n","\n","from augment import augment_train_set\n","\n","import numpy as np\n","import pandas as pd\n","\n","def augment_function(augment_algorithm_name, x_train, y_train, classes, N, limit_N=True):\n","    if augment_algorithm_name == 'as_dtw_dba_augment':\n","        return augment_train_set(x_train, y_train, classes, N,limit_N = limit_N,\n","                                 weights_method_name='as', distance_algorithm='dtw'), 'dtw'\n","\n","def read_data_from_dataset(use_init_clusters=True):\n","    dataset_out_dir = root_dir_output + archive_name + '/' + dataset_name + '/'\n","\n","    x_train = datasets_dict[dataset_name][0]\n","    y_train = datasets_dict[dataset_name][1]\n","    x_test = datasets_dict[dataset_name][2]\n","    y_test = datasets_dict[dataset_name][3]\n","\n","    nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n","    # make the min to zero of labels\n","    y_train, y_test = transform_labels(y_train, y_test)\n","\n","    classes, classes_counts = np.unique(y_train, return_counts=True)\n","\n","    if len(x_train.shape) == 2:  # if univariate\n","        # add a dimension to make it multivariate with one dimension\n","        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","\n","    # maximum number of prototypes which is the minimum count of a class\n","    max_prototypes = min(classes_counts.max() + 1,\n","                         MAX_PROTOTYPES_PER_CLASS + 1)\n","    init_clusters = None\n","\n","    return x_train, y_train, x_test, y_test, nb_classes, classes, max_prototypes, init_clusters\n","\n","# for mesocentre\n","##### you should change these for your directories\n","root_dir = '/content/drive/MyDrive/MSc SS/8th Sem/20XW87 - Data Mining Lab/DTW-Augmentation'\n","root_dir_output = root_dir + 'results/'\n","root_deep_learning_dir = '/content/drive/MyDrive/MSc SS/8th Sem/20XW87 - Data Mining Lab/DTW-Augmentation/dl-tsc/'\n","root_dir_dataset_archive = '/content/drive/MyDrive/MSc SS/8th Sem/20XW87 - Data Mining Lab/DTW-Augmentation/dl-tsc/'\n","\n","# make sure before doing data augmentation to have the models trained without data augmentation\n","# in order to use the same weights init method\n","\n","do_data_augmentation = True\n","do_ensemble = False\n","\n","if do_ensemble:\n","    root_dir_output = root_deep_learning_dir + 'results/ensemble/'\n","else:\n","    if do_data_augmentation:\n","        root_dir_output = root_deep_learning_dir + 'results/resnet_augment/'\n","    else:\n","        root_dir_output = root_deep_learning_dir + 'results/resnet/'\n","\n","\n","# from resnet import Classifier_RESNET\n","\n","results_list = [] # Initialize an empty list to store results\n","\n","# loop the archive names\n","for archive_name in ARCHIVE_NAMES:\n","    # read all the datasets\n","    datasets_dict = read_all_datasets(root_dir_dataset_archive, archive_name)\n","    # loop through all the dataset names\n","    for dataset_name in DATASET_NAMES:\n","        print('dataset_name: ', dataset_name)\n","        # read dataset\n","        x_train, y_train, x_test, y_test, nb_classes, classes, max_prototypes, \\\n","        init_clusters = read_data_from_dataset(use_init_clusters=False)\n","\n","        # specify the output directory for this experiment\n","        output_dir = root_dir_output + archive_name + '/' + dataset_name + '/'\n","\n","        _, classes_counts = np.unique(y_train, return_counts=True)\n","        # this means that all classes will have a number of time series equal to\n","        # nb_prototypes\n","        nb_prototypes = classes_counts.max()\n","\n","        temp = output_dir\n","        # create the directory if not exists\n","        output_dir = create_directory(output_dir)\n","        # check if directory already exists\n","        if output_dir is None:\n","            print('Already_done')\n","            print(temp)\n","            continue\n","\n","        if do_ensemble==False:\n","            # create the resnet classifier\n","            classifier = Classifier_RESNET(output_dir, x_train.shape[1:],\n","                                           nb_classes, nb_prototypes, classes,\n","                                           verbose=True, load_init_weights=do_data_augmentation)\n","            if do_data_augmentation:\n","                # augment the dataset\n","                syn_train_set, distance_algorithm = augment_function('as_dtw_dba_augment',\n","                                                                     x_train, y_train, classes,\n","                                                                     nb_prototypes,limit_N=False)\n","                # get the synthetic train and labels\n","                syn_x_train, syn_y_train = syn_train_set\n","                # concat the synthetic with the reduced random train and labels\n","                aug_x_train = np.array(x_train.tolist() + syn_x_train.tolist())\n","                aug_y_train = np.array(y_train.tolist() + syn_y_train.tolist())\n","\n","                print(np.unique(y_train,return_counts=True))\n","                print(np.unique(aug_y_train,return_counts=True))\n","\n","                y_pred = classifier.fit(aug_x_train, aug_y_train, x_test,\n","                                        y_test)\n","            else:\n","                # no data augmentation\n","                y_pred = classifier.fit(x_train, y_train, x_test,\n","                                    y_test)\n","\n","            df_metrics = calculate_metrics(y_test, y_pred, 0.0)\n","            df_metrics.to_csv(output_dir + 'df_metrics.csv', index=False)\n","            print('DONE')\n","            create_directory(output_dir+'DONE')\n","            # Append the results to the list\n","            # Add classifier_name, archive_name for plot_pairwise\n","            results_list.append({'dataset_name': dataset_name,\n","                                 'classifier_name': 'resnet' if not do_data_augmentation else 'resnet_augment',\n","                                 'archive_name': archive_name,\n","                                 'accuracy': df_metrics['accuracy'][0]}) # Assuming accuracy is the first element\n","\n","\n","        else:\n","            # for ensemble you will have to compute both models in order to ensemble them\n","            from ensemble import Classifier_ENSEMBLE\n","            classifier_ensemble = Classifier_ENSEMBLE(output_dir, x_train.shape[1:], nb_classes, False)\n","            classifier_ensemble.fit(x_test, y_test)\n","\n","\n","# Create a DataFrame from the results list\n","results_df = pd.DataFrame(results_list)\n","\n","if do_data_augmentation == True:\n","# plot pairwise once all results are computed for resnet and resnet_augment and ensemble\n","  plot_pairwise(root_deep_learning_dir,root_dir_dataset_archive, 'resnet', 'resnet_augment', title=\"Model Accuracy comparison\")"],"metadata":{"id":"lQXliU90jDi0","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1744864688800,"user_tz":-330,"elapsed":311505,"user":{"displayName":"21PW21 - RAM MURUGAN S","userId":"00559182924095047839"}},"outputId":"886bc5aa-1f2b-466a-fe69-a1f196e2372a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset_name:  BirdChicken\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\n","\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n","\n"," input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)              \u001b[38;5;34m0\u001b[0m  -                 \n"," (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n","\n"," conv1d (\u001b[38;5;33mConv1D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)           \u001b[38;5;34m576\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n","\n"," batch_normalization  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)           \u001b[38;5;34m256\u001b[0m  conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," activation           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m20,544\u001b[0m  activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)           \u001b[38;5;34m256\u001b[0m  conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," activation_1         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)           \u001b[38;5;34m128\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n","\n"," conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u001b[38;5;34m12,352\u001b[0m  activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)           \u001b[38;5;34m256\u001b[0m  conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)           \u001b[38;5;34m256\u001b[0m  conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," add (\u001b[38;5;33mAdd\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n","                                                     batch_normalizat \n","\n"," activation_2         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m0\u001b[0m  add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m65,664\u001b[0m  activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," activation_3         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m82,048\u001b[0m  activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," activation_4         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)        \u001b[38;5;34m8,320\u001b[0m  activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m49,280\u001b[0m  activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," add_1 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n","                                                     batch_normalizat \n","\n"," activation_5         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)      \u001b[38;5;34m131,200\u001b[0m  activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," activation_6         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m82,048\u001b[0m  activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," activation_7         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u001b[38;5;34m49,280\u001b[0m  activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m512\u001b[0m  conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n"," (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n","\n"," add_2 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n","                                                     batch_normalizat \n","\n"," activation_8         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n"," (\u001b[38;5;33mActivation\u001b[0m)                                                          \n","\n"," global_average_poo  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n"," (\u001b[38;5;33mGlobalAveragePool\u001b[0m                                                   \n","\n"," dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 \u001b[38;5;34m258\u001b[0m  global_average_p \n","\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n","\n"," input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n","\n"," conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n","\n"," batch_normalization  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," activation           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span>  activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," activation_1         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n","\n"," conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span>  activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n","                                                     batch_normalizat \n","\n"," activation_2         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span>  activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," activation_3         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span>  activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," activation_4         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span>  activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span>  activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n","                                                     batch_normalizat \n","\n"," activation_5         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span>  activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," activation_6         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span>  activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," activation_7         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span>  activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n","\n"," add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n","                                                     batch_normalizat \n","\n"," activation_8         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n","\n"," global_average_poo  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span>                                                   \n","\n"," dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>  global_average_p \n","\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m506,818\u001b[0m (1.93 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">506,818</span> (1.93 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m504,258\u001b[0m (1.92 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">504,258</span> (1.92 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(array([0, 1]), array([10, 10]))\n","(array([0, 1]), array([20, 20]))\n","\u001b[1m 6/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5562 - loss: 0.7776 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 164ms/step - accuracy: 0.6183 - loss: 0.6926 - val_accuracy: 0.6500 - val_loss: 0.6718 - learning_rate: 0.0010\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","DONE\n","dataset_name:  ECGFiveDays\n","Already_done\n","/content/drive/MyDrive/MSc SS/8th Sem/20XW87 - Data Mining Lab/DTW-Augmentation/dl-tsc/results/resnet_augment/UCR_TS_Archive_2015/ECGFiveDays/\n","dataset_name:  Meat\n","Already_done\n","/content/drive/MyDrive/MSc SS/8th Sem/20XW87 - Data Mining Lab/DTW-Augmentation/dl-tsc/results/resnet_augment/UCR_TS_Archive_2015/Meat/\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/MSc SS/8th Sem/20XW87 - Data Mining Lab/DTW-Augmentation/utils/utils.py:216: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n","  res = pd.concat((res, df_metrics), axis=0, sort=False)\n"]},{"output_type":"stream","name":"stdout","text":["Wins 1\n","Draws 1\n","Losses 1\n","0.7815112949987133\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/scipy/stats/_wilcoxon.py:199: UserWarning: Sample size too small for normal approximation.\n","  temp = _wilcoxon_iv(x, y, zero_method, correction, alternative, method, axis)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Example: 3 points in 2D space\n","x = np.array([[1.0, 2.0],\n","              [2.0, 3.0],\n","              [3.0, 4.0]])\n","\n","y = np.array([[2.0, 2.0],\n","              [3.0, 3.0],\n","              [4.0, 4.0],\n","              [5.0, 5.0]])\n","\n","# Run DTW\n","dist, D = dynamic_time_warping(x, y)\n","print(\"DTW Distance:\", dist)\n","print(\"Cost Matrix D:\\n\", D)\n","\n","# Replace large values (e.g., sys.float_info.max) with NaN for safe plotting\n","safe_D = np.where(D > 1e6, np.nan, D)\n","\n","# Plot safely\n","plt.imshow(safe_D, interpolation='nearest', cmap='Blues')\n","plt.title('DTW Cost Matrix')\n","plt.colorbar()\n","plt.xlabel('y')\n","plt.ylabel('x')\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"3jfcJBbUA9pZ","executionInfo":{"status":"ok","timestamp":1744814309705,"user_tz":-330,"elapsed":366,"user":{"displayName":"21PW21 - RAM MURUGAN S","userId":"00559182924095047839"}},"outputId":"954e06a2-f717-4085-a457-4315a6f29195"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DTW Distance: 2.8284271247461903\n","Cost Matrix D:\n"," [[0.00000000e+000 1.79769313e+308 1.79769313e+308 1.79769313e+308\n","  1.79769313e+308]\n"," [1.79769313e+308 1.00000000e+000 6.00000000e+000 1.90000000e+001\n","  4.40000000e+001]\n"," [1.79769313e+308 2.00000000e+000 2.00000000e+000 7.00000000e+000\n","  2.00000000e+001]\n"," [1.79769313e+308 7.00000000e+000 3.00000000e+000 3.00000000e+000\n","  8.00000000e+000]]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}